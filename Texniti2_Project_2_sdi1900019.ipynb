{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "KSjBCv_NofF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "!pip install contractions\n",
        "import contractions\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install torchmetrics\n",
        "import torchmetrics\n",
        "from torchmetrics import F1Score\n",
        "from torchmetrics import Accuracy\n",
        "from torchmetrics import Precision\n",
        "from torchmetrics import Recall\n",
        "from torchmetrics import ROC\n",
        "from torchmetrics.classification import BinaryROC\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from collections import Counter\n",
        "import string"
      ],
      "metadata": {
        "id": "u1XvZ0LgodB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open dataset"
      ],
      "metadata": {
        "id": "WMLMvepvoWFy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FiHBR1Gkag0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('drive/MyDrive/imdb-reviews.csv', sep='\\t')\n",
        "\n",
        "test_df = None\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing"
      ],
      "metadata": {
        "id": "V5BIGVHwonph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove unnecessary columns and add sentiment column"
      ],
      "metadata": {
        "id": "7LWCY5jyotLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_cols(df):\n",
        "  # διώχνω τα άχρηστα δεδομένα πχ. url rating\n",
        "  df = df.drop(['url'], axis=1)\n",
        "\n",
        "  # add sentiment col 0 for negative 1 for positive\n",
        "  df['sentiment'] = np.where(df['rating']>4.0, 1, 0)\n",
        "\n",
        "  # no more need for col rating\n",
        "  df = df.drop(['rating'], axis=1)\n",
        "\n",
        "  return df\n",
        "\n",
        "df = remove_cols(df)\n",
        "\n",
        "if test_df is not None:\n",
        "  test_df = remove_cols(test_df)"
      ],
      "metadata": {
        "id": "iHRlOghVo3rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "zXvCJA0eqrp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean review from html tags, numbers, punctuation and stopwords."
      ],
      "metadata": {
        "id": "dYcLqp52pMcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].str.lower()\n",
        "df['review'] = df['review'].replace('<br />', ' ', regex=True)\n",
        "df['review'] = df['review'].replace('<[^<]+?>', '', regex=True)\n",
        "\n",
        "if test_df is not None:\n",
        "  test_df['review'] = test_df['review'].str.lower()\n",
        "  test_df['review'] = test_df['review'].replace('<br />', ' ', regex=True)\n",
        "  test_df['review'] = test_df['review'].replace('<[^<]+?>', '', regex=True)\n",
        "\n",
        "def clean_review(review):\n",
        "  review = re.sub(r'[^a-zA-Z0-9\\s]', '', review)\n",
        "\n",
        "  return review\n",
        "\n",
        "df['review'] = df['review'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
        "\n",
        "df['review'] = df['review'].apply(lambda x: clean_review(x))\n",
        "\n",
        "if test_df is not None:\n",
        "  test_df['review'] = test_df['review'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
        "\n",
        "  test_df['review'] = test_df['review'].apply(lambda x: clean_review(x))\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "dqQ4P7xlpLcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expand Contractions"
      ],
      "metadata": {
        "id": "zJOoq5TRD92C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_contractions(review):\n",
        "  return contractions.fix(review)\n",
        "\n",
        "df['review'] = df['review'].apply(lambda x: expand_contractions(x))\n",
        "\n",
        "if test_df is not None:\n",
        "  test_df['review'] = test_df['review'].apply(lambda x: expand_contractions(x))\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "kTAUakyQDpiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove stopwords\n"
      ],
      "metadata": {
        "id": "hbsFe-esEG1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('english')\n",
        "stopwords_dict = Counter(stop_words)  # dictionary for faster lookup\n",
        "\n",
        "def remove_stopwords(review):\n",
        "  return ' '.join([word for word in review.split() if word not in stopwords_dict])\n",
        "\n",
        "df['review'] = df['review'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "if test_df is not None:\n",
        "  test_df['review'] = test_df['review'].apply(lambda x: remove_stopwords(x))"
      ],
      "metadata": {
        "id": "JEFsEXY-HCKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove duplicate words from review"
      ],
      "metadata": {
        "id": "FeV_2tB3pdDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_dups(review):\n",
        "  return ' '.join(dict.fromkeys(review.split()))\n",
        "\n",
        "df['review'] = df['review'].apply(lambda x: remove_dups(x))\n",
        "\n",
        "if test_df is not None:\n",
        "  test_df['review'] = test_df['review'].apply(lambda x: remove_dups(x))"
      ],
      "metadata": {
        "id": "TH6Iv2CIpdnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization"
      ],
      "metadata": {
        "id": "56F9CFh2p_1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.tokenize.WhitespaceTokenizer()"
      ],
      "metadata": {
        "id": "fD1squ-cqBHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "o_Ehs5v5qROQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatization(review):\n",
        "    return \" \".join([lemmatizer.lemmatize(w, pos=\"v\") for w in tokenizer.tokenize(review)])\n",
        "\n",
        "df['review'] = df['review'].apply(lemmatization)\n",
        "\n",
        "if test_df is not None:\n",
        "  test_df['review'] = test_df['review'].apply(lemmatization)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "rNRRmNcfqSpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Glove"
      ],
      "metadata": {
        "id": "J_yoZQBE-vOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_input_file = 'glove.6B.300d.txt'\n",
        "w2v_output_file = 'glv_with_w2v_format.txt'\n",
        "\n",
        "dim = 300\n",
        "\n",
        "glove2word2vec(glove_input_file, w2v_output_file)"
      ],
      "metadata": {
        "id": "iolowUwl-wte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Φτιάχνω ένα dictionary για κάθε λέξη το οποίο θα την αντιστοιχεί με το vector της (πχ. dict['the'] = vector_of['the'])"
      ],
      "metadata": {
        "id": "9RbR93eLFNq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(w2v_output_file, 'r') as infile:\n",
        "    w2v = infile.read().splitlines()\n",
        "\n",
        "words = []      # list of words\n",
        "vectors = []    # holds the vector of corresponding word\n",
        "index = 0       # index of word in list of vectors\n",
        "dictionary = {} # word: , index_in_vectors:\n",
        "\n",
        "# first element of w2v is 400000,50 so we dont need that\n",
        "for word_vector_pair in w2v[1:]:\n",
        "    word_vector_pair = word_vector_pair.split()\n",
        "    words.append(word_vector_pair[0])           # add word in list\n",
        "    vectors.append(np.array(word_vector_pair[1:]).astype(float))        # add vector in list (need to convert for later)\n",
        "    dictionary[word_vector_pair[0]] = index     # update dictionary\n",
        "    index += 1\n",
        "print(type(vectors[0][0]))\n",
        "word_vector = {w: vectors[dictionary[w]] for w in words}\n",
        "\n",
        "#word_vector['the']"
      ],
      "metadata": {
        "id": "WzJtYUOJBfny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Για κάθε λέξη σε ένα review θα έχουμε ένα vector dim θέσεων. Το input του νευρωνικού δικτύου θα είναι επίσης dim. Επειδή δε μπορούμε να βάλουμε όλα τα word vectors του review στο input, θα προσθέσουμε τα word vectors και θα τα διαιρέσουμε με το πλήθος των λέξεων του review. Αν κάποια λέξη υπάρχει στο review και όχι στο glove τότε δεν την μετράμε σε αυτή την πρόσθεση επομένως το word vector της θα είναι 0 και θα διαιρέσουμε το άθροισμα με το πλήθος των λέξεων στο review - 1."
      ],
      "metadata": {
        "id": "8fbtBf_0Tm0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_review_vector(df, word_vector, dim):\n",
        "  review_vectors = []  # list with mean vector values of each review\n",
        "  for review in df['review']:\n",
        "    words = review.split(' ')\n",
        "    words_in_glove = 0   # number of words in review\n",
        "    review_vector_mean = np.zeros((len(words),dim))           # we are going to add all the word vectors in review (that also exist in glove)\n",
        "    i=0\n",
        "    for word in words:\n",
        "      if word in word_vector:\n",
        "        review_vector_mean[i] += word_vector[word]\n",
        "        words_in_glove += 1\n",
        "      i+=1\n",
        "    # we now have number of words in review and number of words also in glove\n",
        "    mean = np.sum(review_vector_mean, axis=0)\n",
        "    mean /= words_in_glove\n",
        "    review_vectors.append(mean)\n",
        "\n",
        "  return review_vectors\n",
        "\n",
        "review_vectors = create_review_vector(df, word_vector, dim)\n",
        "\n",
        "print(len(review_vectors))\n",
        "print(len(review_vectors[0]))"
      ],
      "metadata": {
        "id": "rTVYxwx7UGqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = df['sentiment'].apply(lambda x: float(x))  # must convert for y_pred = model(x_batch)\n",
        "y1 = y1.to_numpy()\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(np.array(review_vectors), y1, test_size = 0.1, random_state=42)\n",
        "\n",
        "X_train = torch.tensor(X_train)\n",
        "X_test = torch.tensor(X_test)\n",
        "\n",
        "Y_train = torch.squeeze(torch.from_numpy(Y_train))\n",
        "Y_test = torch.squeeze(torch.from_numpy(Y_test))\n",
        "\n",
        "if test_df is not None:\n",
        "  y1_val = test_df['sentiment'].apply(lambda x: float(x))  # must convert for y_pred = model(x_batch)\n",
        "  y1_val = y1_val.to_numpy()\n",
        "  # y_test_val = torch.squeeze(torch.from_numpy(y1_val))\n",
        "  # print(y_test_val.shape)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "id": "QgbMwlO9w4J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a Neural Network"
      ],
      "metadata": {
        "id": "r4a2gioMsxVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    #def __init__(self, D_in, H1, H2, H3, D_out):\n",
        "    def __init__(self, D_in, H1, H2, D_out):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(D_in, H1)\n",
        "        nn.init.kaiming_uniform_(self.linear1.weight, mode='fan_in', nonlinearity='relu')\n",
        "        self.relu_1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "        self.linear2 = nn.Linear(H1, H2)\n",
        "        nn.init.kaiming_uniform_(self.linear2.weight, mode='fan_in', nonlinearity='relu')\n",
        "        self.relu_2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        self.linear3 = nn.Linear(H2, D_out)\n",
        "\n",
        "        # self.linear3 = nn.Linear(H2, H3)\n",
        "        # self.relu_3 = nn.ReLU()\n",
        "        # self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        # self.linear4 = nn.Linear(H3, D_out)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = self.linear1(x)\n",
        "        out = self.relu_1(h1)\n",
        "\n",
        "        h2 = self.linear2(h1)\n",
        "        out = self.relu_2(h2)\n",
        "\n",
        "        # h3 = self.linear3(h2)\n",
        "        # out = self.relu_3(h3)\n",
        "\n",
        "        # out = self.linear4(h3)\n",
        "\n",
        "        out = self.linear3(h2)\n",
        "\n",
        "        return torch.sigmoid(out)\n",
        "        #return out"
      ],
      "metadata": {
        "id": "TZcRMSqFs0rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "#Define layer sizes\n",
        "D_in = X_train.shape[1]\n",
        "# H1 = 128\n",
        "# H2 = 64\n",
        "# H3 = 16\n",
        "H1 = 64\n",
        "H2 = 16\n",
        "D_out = 1\n",
        "\n",
        "#Define Hyperparameters\n",
        "learning_rate = 1e-4\n",
        "\n",
        "#Initialise model, loss, optimizer\n",
        "#model = Net(D_in, H1, H2, H3, D_out)\n",
        "model = Net(D_in, H1, H2, D_out)\n",
        "\n",
        "#loss_func = nn.MSELoss(reduction='sum')\n",
        "#loss_func = nn.CrossEntropyLoss()  # + sigmoid(out) -> 1500 loss\n",
        "loss_func = nn.BCELoss()            # + sigmoid(out)\n",
        "#loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate,weight_decay=1e-4)\n",
        "optimizer = torch.optim.Adamax(model.parameters(),lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = torch.optim.RMSprop(model.parameters(),lr=learning_rate,weight_decay=1e-3)\n",
        "#optimizer = torch.optim.Adagrad(model.parameters(),lr=learning_rate,weight_decay=1e-4)\n",
        "\n",
        "#Initialise dataloader\n",
        "dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "#initialise test dataloader\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)"
      ],
      "metadata": {
        "id": "IyQmoxzKs2Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "ChaUuS3mA8If"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "f1_score = F1Score(task=\"binary\", num_classes=1)\n",
        "acc = Accuracy(task=\"binary\", num_classes=1)\n",
        "rec = Recall(task=\"binary\", num_classes=1)\n",
        "prec = Precision(task=\"binary\", num_classes=1)\n",
        "\n",
        "train_mean_accuracy = []\n",
        "train_mean_loss = []\n",
        "train_mean_roc = []\n",
        "train_mean_fpr = []\n",
        "train_mean_tpr = []\n",
        "train_mean_thresholds = []\n",
        "\n",
        "test_mean_accuracy = []\n",
        "test_mean_loss = []\n",
        "test_mean_fpr = []\n",
        "test_mean_tpr = []\n",
        "test_mean_thresholds = []\n",
        "\n",
        "for epoch in range(100):\n",
        "  batch_losses = []\n",
        "  accuracy = []\n",
        "  precision = []\n",
        "  recall = []\n",
        "  f1 = []\n",
        "  fpr_list = []\n",
        "  tpr_list = []\n",
        "  thresholds_list = []\n",
        "  test_batch_losses = []\n",
        "  test_accuracy = []\n",
        "  test_precision = []\n",
        "  test_recall = []\n",
        "  test_f1 = []\n",
        "  test_fpr_list = []\n",
        "  test_tpr_list = []\n",
        "  test_thresholds_list = []\n",
        "  for x_batch, y_batch in dataloader:\n",
        "    y_pred = model(x_batch.float())\n",
        "\n",
        "    loss = loss_func(torch.squeeze(y_pred), y_batch.float())\n",
        "    batch_losses.append(loss.item())\n",
        "\n",
        "    precision.append(prec(torch.squeeze(torch.round(y_pred)), y_batch))\n",
        "    accuracy.append(acc(torch.squeeze(torch.round(y_pred)), y_batch))\n",
        "    f1.append(f1_score(torch.squeeze(torch.round(y_pred)), y_batch))\n",
        "    recall.append(rec(torch.squeeze(torch.round(y_pred)), y_batch))\n",
        "\n",
        "    #Delete previously stored gradients\n",
        "    optimizer.zero_grad()\n",
        "    #Perform backpropagation starting from the loss calculated in this epoch\n",
        "    loss.backward()\n",
        "    #Update model's weights based on the gradients calculated during backprop\n",
        "    optimizer.step()\n",
        "\n",
        "  for test_x, test_y in test_dataloader:\n",
        "    y_pred = model(test_x.float())\n",
        "\n",
        "    loss = loss_func(torch.squeeze(y_pred), test_y.float())\n",
        "    test_batch_losses.append(loss.item())\n",
        "\n",
        "    test_precision.append(prec(torch.squeeze(torch.round(y_pred)), test_y))\n",
        "    test_accuracy.append(acc(torch.squeeze(torch.round(y_pred)), test_y))\n",
        "    test_f1.append(f1_score(torch.squeeze(torch.round(y_pred)), test_y))\n",
        "    test_recall.append(rec(torch.squeeze(torch.round(y_pred)), test_y))\n",
        "\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(np.round_(y_pred.detach().numpy()), test_y, pos_label=1)\n",
        "    fpr_list.append(fpr)\n",
        "    tpr_list.append(tpr)\n",
        "    thresholds_list.append(thresholds)\n",
        "\n",
        "  train_mean_accuracy.append(sum(accuracy)/len(dataloader))\n",
        "  test_mean_accuracy.append(sum(test_accuracy)/len(test_dataloader))\n",
        "  train_mean_loss.append(sum(batch_losses)/len(dataloader))\n",
        "  test_mean_loss.append(sum(test_batch_losses)/len(test_dataloader))\n",
        "\n",
        "  test_mean_fpr.append(sum(fpr_list)/len(test_dataloader))\n",
        "  test_mean_tpr.append(sum(tpr_list)/len(test_dataloader))\n",
        "\n",
        "  print(f\"Epoch {epoch:3}: Accuracy = {sum(accuracy)/len(dataloader):.5f} -  Test Accuracy = {sum(test_accuracy)/len(test_dataloader):.5f}\")\n",
        "  print(f\"Epoch {epoch:3}: Precision = {sum(precision)/len(dataloader):.5f} -  Test Precision = {sum(test_precision)/len(test_dataloader):.5f}\")\n",
        "  print(f\"Epoch {epoch:3}: Recall = {sum(recall)/len(dataloader):.5f} -  Test Recall = {sum(test_recall)/len(test_dataloader):.5f}\")\n",
        "  print(f\"Epoch {epoch:3}: F1 = {sum(f1)/len(dataloader):.5f} -  Test F1 = {sum(test_f1)/len(test_dataloader):.5f}\")\n",
        "  print(f\"Epoch {epoch:3}: Test Fpr = {sum(fpr_list)/len(test_dataloader)}\")\n",
        "  print(f\"Epoch {epoch:3}: Test Tpr = {sum(tpr_list)/len(test_dataloader)}\")\n",
        "  print(f\"Epoch {epoch:3}: Loss = {sum(batch_losses)/len(dataloader):.5f} -  Test Loss = {sum(test_batch_losses)/len(test_dataloader):.5f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "0cxMzTDTBF7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization Learning Curves: Learning curves calculated on the metric by which the parameters of the model are being optimized e.g. loss"
      ],
      "metadata": {
        "id": "gOnjg-QQriDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_lc(train, test, title, ylabel, loc):\n",
        "  figure(figsize=(8,8))\n",
        "  plt.plot(train)\n",
        "  plt.plot(test)\n",
        "  plt.title(title)\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.legend(['train', 'test'], loc=loc)\n",
        "  plt.show()\n",
        "\n",
        "plot_lc(train_mean_accuracy, test_mean_accuracy, \"Learning Curve Accuracy\", \"Accuracy\", 'lower right')\n",
        "print()\n",
        "plot_lc(train_mean_loss, test_mean_loss, \"Learning Curve Loss\", \"Loss\", 'upper right')"
      ],
      "metadata": {
        "id": "Rk7081xstc15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC\n"
      ],
      "metadata": {
        "id": "fhhlrGwo9kKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model(X_test.float())\n",
        "display = metrics.RocCurveDisplay.from_predictions(Y_test, y_pred.detach().numpy())"
      ],
      "metadata": {
        "id": "Ya1rT3Pj9lJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy on validation (given) set"
      ],
      "metadata": {
        "id": "jELQBANyp8d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if test_df is not None:\n",
        "  val_review_vectors = create_review_vector(test_df, word_vector, dim)\n",
        "\n",
        "  x_val = np.array(val_review_vectors)\n",
        "  x_val = torch.tensor(x_val)\n",
        "  y_pred = model(x_val.float().clone().detach().requires_grad_(True))\n",
        "  y1_val = torch.squeeze(torch.from_numpy(y1_val))\n",
        "\n",
        "  print(prec(torch.squeeze(torch.round(y_pred)), y1_val))\n",
        "  print(acc(torch.squeeze(torch.round(y_pred)), y1_val))\n",
        "  print(f1_score(torch.squeeze(torch.round(y_pred)), y1_val))\n",
        "  print(rec(torch.squeeze(torch.round(y_pred)), y1_val))\n",
        "\n"
      ],
      "metadata": {
        "id": "Y8uUdA7-p-ul"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}